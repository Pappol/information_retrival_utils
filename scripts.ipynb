{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(arr):\n",
    "    if not arr:  # Check if the array is empty\n",
    "        return []\n",
    "\n",
    "    min_val = min(arr)\n",
    "    max_val = max(arr)\n",
    "    \n",
    "    if min_val == max_val:  # Check if all values in array are the same\n",
    "        return [0] * len(arr)\n",
    "\n",
    "    # Apply min-max normalization and round to 3 decimal places\n",
    "    return [round((x - min_val) / (max_val - min_val), 3) for x in arr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.5]\n"
     ]
    }
   ],
   "source": [
    "#example of use\n",
    "arr = [2,12,7]\n",
    "print(min_max_normalize(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmean clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return np.sqrt(np.sum((np.array(point1) - np.array(point2)) ** 2))\n",
    "\n",
    "def classify_points(points, centroids):\n",
    "    \"\"\"Classify points based on the closest centroid using K-means clustering.\n",
    "    In case of equidistant points, choose the cluster with the lowest index.\n",
    "\n",
    "    Args:\n",
    "    points (list of lists): The points to classify.\n",
    "    centroids (list of lists): The centroids to use for classification.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of indices indicating the closest centroid for each point.\n",
    "    \"\"\"\n",
    "    classifications = []\n",
    "    for point in points:\n",
    "        distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
    "        min_distance = min(distances)\n",
    "        # Find indices of all centroids that have the minimum distance\n",
    "        min_indices = [i for i, d in enumerate(distances) if d == min_distance]\n",
    "        # Choose the centroid with the lowest index among those\n",
    "        classification = min(min_indices)\n",
    "        classifications.append(classification)\n",
    "    return classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point (3, 1, 0, 4) is classified to centroid (1.5, 2.5, 1, 2)\n",
      "Point (1, 3, 4.5, 5) is classified to centroid (3, 5, 4, 4.5)\n",
      "Point (6, 3, 2, 0) is classified to centroid (2, 3.5, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "points = [(3,1,0,4), (1,3,4.5,5), (6,3,2,0)]\n",
    "centroids = [(3,5,4,4.5), (1.5,2.5,1,2),(2,3.5,1,0)]\n",
    "\n",
    "# Classify the points\n",
    "classifications = classify_points(points, centroids)\n",
    "\n",
    "# Output the classification result\n",
    "for point, classification in zip(points, classifications):\n",
    "    print(f\"Point {point} is classified to centroid {centroids[classification]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichlet_smoothing(term_doc_matrix, term_index, doc_index, mu=6):\n",
    "\n",
    "    # Total count of the term in the entire collection\n",
    "    term_count_in_collection = sum(row[term_index] for row in term_doc_matrix)\n",
    "\n",
    "    # Length of the document (sum of counts of all terms in the document)\n",
    "    doc_length = sum(term_doc_matrix[doc_index])\n",
    "\n",
    "    # Count of the term in the document\n",
    "    term_count_in_doc = term_doc_matrix[doc_index][term_index]\n",
    "\n",
    "    # Total count of all terms in the collection\n",
    "    total_term_count = sum(sum(row) for row in term_doc_matrix)\n",
    "\n",
    "    # Calculate the probability of the term in the empirical language model of the document\n",
    "    probability = (term_count_in_doc + mu * (term_count_in_collection / total_term_count)) / (doc_length + mu)\n",
    "\n",
    "    return probability\n",
    "\n",
    "# Example usage\n",
    "# term_doc_matrix = [[2, 3], [0, 1], [1, 0]] # Example term-document matrix\n",
    "# term_index = 0  # Index of the term\n",
    "# doc_index = 1  # Index of the document\n",
    "# probability = dirichlet_smoothing(term_doc_matrix, term_index, doc_index)\n",
    "# print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb Cella 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mu \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Probability of term5 in doc1 with Dirichlet smoothing\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m prob \u001b[39m=\u001b[39m dirichlet_smoothing(term_document_matrix, term_index, doc_index, mu)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProbability of term5 in doc1 is \u001b[39m\u001b[39m{\u001b[39;00mprob\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb Cella 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdirichlet_smoothing\u001b[39m(term_doc_matrix, term_index, doc_index, mu\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Total count of the term in the entire collection\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     term_count_in_collection \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(row[term_index] \u001b[39mfor\u001b[39;49;00m row \u001b[39min\u001b[39;49;00m term_doc_matrix)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Length of the document (sum of counts of all terms in the document)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     doc_length \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(term_doc_matrix[doc_index])\n",
      "\u001b[1;32m/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb Cella 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdirichlet_smoothing\u001b[39m(term_doc_matrix, term_index, doc_index, mu\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Total count of the term in the entire collection\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     term_count_in_collection \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(row[term_index] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m term_doc_matrix)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Length of the document (sum of counts of all terms in the document)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pappol/Desktop/uni/text_mining/Exam/information_retrival_utils/scripts.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     doc_length \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(term_doc_matrix[doc_index])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "term_document_matrix = np.array([\n",
    "    [1, 1, 2, 1],  # term1\n",
    "    [0, 2, 0, 1],  # term2\n",
    "    [2, 0, 1, 0],  # term3\n",
    "    [4, 0, 1, 2],  # term4\n",
    "    [1, 2, 1, 0]   # term5\n",
    "])\n",
    "\n",
    "# Parameters\n",
    "term_index = 4\n",
    "doc_index = 0\n",
    "mu = 6\n",
    "\n",
    "# Probability of term5 in doc1 with Dirichlet smoothing\n",
    "prob = dirichlet_smoothing(term_document_matrix, term_index, doc_index, mu)\n",
    "\n",
    "print(f\"Probability of term5 in doc1 is {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of term5 in doc1 is 0.149\n",
      "Probability of term4 in the collection is 0.318\n",
      "Probability of term2 in doc3 is 0.074\n",
      "Term with lowest probability in doc2 is term3\n",
      "Document with highest score is doc3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Term-document matrix as provided\n",
    "term_document_matrix = np.array([\n",
    "    [1, 1, 2, 1],  # term1\n",
    "    [0, 2, 0, 1],  # term2\n",
    "    [2, 0, 1, 0],  # term3\n",
    "    [4, 0, 1, 2],  # term4\n",
    "    [1, 2, 1, 0]   # term5\n",
    "])\n",
    "\n",
    "# Dirichlet smoothing parameter\n",
    "mu = 6\n",
    "\n",
    "# Calculate the total number of words in each document\n",
    "doc_lengths = term_document_matrix.sum(axis=0)\n",
    "\n",
    "# Calculate the total count of each term in the collection (sum over all documents)\n",
    "term_frequencies = term_document_matrix.sum(axis=1)\n",
    "\n",
    "# Total number of words in the collection\n",
    "collection_length = term_frequencies.sum()\n",
    "\n",
    "# Calculate the probability of each term in the collection\n",
    "term_prob_collection = term_frequencies / collection_length\n",
    "\n",
    "# Function to calculate the smoothed probability of a term in a document\n",
    "def dirichlet_smoothed_probability(term_idx, doc_idx, term_document_matrix, mu, term_prob_collection):\n",
    "    term_count = term_document_matrix[term_idx, doc_idx]\n",
    "    doc_length = doc_lengths[doc_idx]\n",
    "    prob_term_collection = term_prob_collection[term_idx]\n",
    "    return (term_count + mu * prob_term_collection) / (doc_length + mu)\n",
    "\n",
    "# Calculate the probability of term5 in the empirical language model of doc1\n",
    "prob_term5_doc1 = dirichlet_smoothed_probability(4, 0, term_document_matrix, mu, term_prob_collection)\n",
    "\n",
    "# Calculate the probability of term4 in the background language model (collection)\n",
    "prob_term4_collection = term_prob_collection[3]\n",
    "\n",
    "# Calculate the probability of term2 in the smoothed language model of doc3\n",
    "prob_term2_doc3 = dirichlet_smoothed_probability(1, 2, term_document_matrix, mu, term_prob_collection)\n",
    "\n",
    "# Calculate the smoothed probabilities for all terms in doc2 for finding the term with lowest probability\n",
    "prob_terms_doc2 = [dirichlet_smoothed_probability(term_idx, 1, term_document_matrix, mu, term_prob_collection) for term_idx in range(term_document_matrix.shape[0])]\n",
    "lowest_prob_term_doc2 = np.argmin(prob_terms_doc2) + 1 # adding 1 to match term numbering\n",
    "\n",
    "# Function to calculate the score of a document for a given query\n",
    "def document_score(query_terms, doc_idx, term_document_matrix, mu, term_prob_collection):\n",
    "    score = 1\n",
    "    for term in query_terms:\n",
    "        term_idx = int(term[-1]) - 1  # Convert term to index (e.g., term1 to 0)\n",
    "        score *= dirichlet_smoothed_probability(term_idx, doc_idx, term_document_matrix, mu, term_prob_collection)\n",
    "    return score\n",
    "\n",
    "# Calculate the scores for each document for the given query\n",
    "query = [\"term1\", \"term3\", \"term5\"]\n",
    "scores = [document_score(query, doc_idx, term_document_matrix, mu, term_prob_collection) for doc_idx in range(term_document_matrix.shape[1])]\n",
    "top_scoring_doc = np.argmax(scores) + 1 # adding 1 to match document numbering\n",
    "\n",
    "#print with 3 decimal places (prob_term5_doc1, prob_term4_collection, prob_term2_doc3, lowest_prob_term_doc2, top_scoring_doc)\n",
    "print(f\"Probability of term5 in doc1 is {prob_term5_doc1:.3f}\")\n",
    "print(f\"Probability of term4 in the collection is {prob_term4_collection:.3f}\")\n",
    "print(f\"Probability of term2 in doc3 is {prob_term2_doc3:.3f}\")\n",
    "print(f\"Term with lowest probability in doc2 is term{lowest_prob_term_doc2}\")\n",
    "print(f\"Document with highest score is doc{top_scoring_doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@5 for system A: 3.861\n",
      "DCG@5 for system B: 4.893\n",
      "NDCG@10 for system A: 0.693\n",
      "NDCG@10 for system B: 0.780\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def dcg_at_value(ranked_documents, ground_truth, value):\n",
    "    dcg = ground_truth.get(ranked_documents[0], 0)\n",
    "    for i, doc_id in enumerate(ranked_documents[1:value], start=2):\n",
    "        relevance_score = ground_truth.get(doc_id, 0)\n",
    "        dcg += relevance_score / math.log2(i)  # +2 because we start counting ranks from 1 and log base 2\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(ranked_documents, ground_truth, k):\n",
    "    dcg_max = dcg_at_value(sorted(ground_truth, key=ground_truth.get, reverse=True), ground_truth, k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return dcg_at_value(ranked_documents, ground_truth, k) / dcg_max\n",
    "\n",
    "\n",
    "ground_truth_scores = {1: 3, \n",
    "                       2: 2, \n",
    "                       3: 1, \n",
    "                       7: 3}  # Mapping from the document ID to its score\n",
    "\n",
    "# Rankings from the image\n",
    "system_a_ranking = [10, 7, 9, 8, 2, 1, 3, 4, 5, 6]\n",
    "system_b_ranking = [3, 2, 1, 4, 5, 7, 8, 10, 9, 6]\n",
    "\n",
    "# Calculate DCG@5 for both systems\n",
    "dcg_at_5_system_a = dcg_at_value(system_a_ranking, ground_truth_scores, 5)\n",
    "dcg_at_5_system_b = dcg_at_value(system_b_ranking, ground_truth_scores, 5)\n",
    "\n",
    "print(f\"DCG@5 for system A: {dcg_at_5_system_a:.3f}\")\n",
    "print(f\"DCG@5 for system B: {dcg_at_5_system_b:.3f}\")\n",
    "\n",
    "# calculate ndcg@10 for both systems\n",
    "ndcg_at_10_system_a = ndcg_at_k(system_a_ranking, ground_truth_scores, 10)\n",
    "ndcg_at_10_system_b = ndcg_at_k(system_b_ranking, ground_truth_scores, 10)\n",
    "\n",
    "print(f\"NDCG@10 for system A: {ndcg_at_10_system_a:.3f}\")\n",
    "print(f\"NDCG@10 for system B: {ndcg_at_10_system_b:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
